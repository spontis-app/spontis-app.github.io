name: scrape

on:
  workflow_dispatch:      # manuell kjøring fra Actions-tab
  schedule:
    - cron: "17 06 * * *" # kjør daglig 06:17 UTC (juster gjerne)

concurrency:
  group: scrape
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: write      # nødvendig for å pushe til repoet
      pull-requests: write # ikke strengt nødvendig her, men greit å ha

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt

      - name: Run auto scraper
        env:
          SPONTIS_RUN_STATUS: "success"
          SPONTIS_RUN_MESSAGE: "GitHub Actions run #${{ github.run_number }}"
        run: |
          python auto_scraper.py

      - name: Commit & push if data changed
        run: |
          if [[ -n "$(git status --porcelain)" ]]; then
            git config user.name "spontis-bot"
            git config user.email "bot@users.noreply.github.com"
            git add data/events.json data/generated docs/discovery scraper/generated || true
            git commit -m "[auto-update] refreshed sources" || true
            git push
          else
            echo "No changes to data/events.json"
          fi
